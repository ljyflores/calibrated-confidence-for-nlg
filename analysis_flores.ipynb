{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/mila/f/floresl/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/mila/f/floresl/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/mila/f/floresl/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils_analysis import prepare_scores\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils_tail_probs import softmax, tail_index\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import json\n",
    "from src.eval import calculate_bleu\n",
    "from src.eval import calculate_rouge_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/f/floresl/beam-search/utils_analysis.py:45: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  abs(spearmanr(ground_truth_score, confidence_score_dict[str(k)]).statistic)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/flores/test.csv\")\n",
    "\n",
    "# \"results/bart/r1/bart-base_data_flores_checkpoint-300_flores.json\",\n",
    "# \"results/bart/r2/bart-base_data_flores_checkpoint-300_flores.json\",\n",
    "# \"results/bart/r3/bart-base_data_flores_checkpoint-1000_flores.json\",\n",
    "# \"results/t5/r1/flan-t5-base_data_flores_checkpoint-300_flores.json\",\n",
    "# \"results/t5/r2/flan-t5-base_data_flores_checkpoint-300_flores.json\",\n",
    "# \"results/t5/r3/flan-t5-base_data_flores_checkpoint-1000_flores.json\",\n",
    "\n",
    "results = prepare_scores(\n",
    "    \"results/flan-t5-base_data_flores_checkpoint-1000_flores.json\",\n",
    "    df[\"target\"],\n",
    "    \"bleu\",\n",
    ")\n",
    "\n",
    "baseline_probs = json.load(\n",
    "    open(\n",
    "        \"results/t5_baseline/google_flan-t5-base_flores.json\",\n",
    "        \"r\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_score_log_probs = pd.DataFrame(results.scores_by_beam[\"beam_score_log_probs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length_normalized_log_probs    0.080417\n",
       "mean_token_entropy            -0.069656\n",
       "dropout_bleu_variance          0.407076\n",
       "dropout_meteor_score           0.477018\n",
       "dropout_entropy               -0.226441\n",
       "dropout_disagreement           0.055734\n",
       "bleu                           1.000000\n",
       "beam_score_ratios_99           0.222818\n",
       "beam_score_log_probs_99        0.020158\n",
       "beam_score_top_k_99            0.050499\n",
       "beam_score_impt_wt_99         -0.050880\n",
       "Name: bleu, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.scores_dataframe.drop([\"sentences\", \"dropout_sentences\"], axis=1).corr(\n",
    "    method=\"spearman\"\n",
    ")[\"bleu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tail Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.33566514658213226, pvalue=4.499744944356827e-28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tail_indices = []\n",
    "for i in range(len(beam_score_log_probs)):\n",
    "    probs = softmax(beam_score_log_probs.iloc[i].to_numpy(), temperature=1)\n",
    "    tail_indices.append(tail_index(probs))\n",
    "\n",
    "spearmanr(tail_indices, results.scores_dataframe[\"bleu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_log_probs = baseline_probs[\"beam_score_log_probs\"]\n",
    "baseline_log_probs = pd.DataFrame(baseline_log_probs).values\n",
    "\n",
    "beam_score_log_probs = beam_score_log_probs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.31346563399159383, pvalue=1.6426005234166847e-24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_distances = []\n",
    "for i in range(1012):\n",
    "    js = jensenshannon(\n",
    "        softmax(beam_score_log_probs[i], temperature=1),\n",
    "        softmax(baseline_log_probs[i], temperature=1),\n",
    "    )\n",
    "    js_distances.append(js)\n",
    "spearmanr(js_distances, results.scores_dataframe[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.3362153416100313, pvalue=3.639991728735621e-28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_distances = []\n",
    "for i in range(1012):\n",
    "    js = jensenshannon(\n",
    "        softmax(beam_score_log_probs[i], temperature=1), np.array([1 / 100] * 100)\n",
    "    )\n",
    "    js_distances.append(js)\n",
    "spearmanr(js_distances, results.scores_dataframe[\"bleu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_sentences = results.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_scores(target: str, predictions: list[str]):\n",
    "    return list(\n",
    "        map(\n",
    "            lambda pred: calculate_bleu([pred], [[target]]),\n",
    "            predictions,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1239057/3743040825.py:10: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_w_score = spearmanr(beam_score_log_probs[i], quality_scores).statistic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n",
      "float division by zero\n"
     ]
    }
   ],
   "source": [
    "weighted_avgs = list[float]()\n",
    "corr_w_scores = list[float]()\n",
    "for i in range(1012):\n",
    "    quality_scores = get_list_of_scores(df[\"target\"][i], results.sentences[i])\n",
    "    weighted_avg = (\n",
    "        float(np.average(beam_score_log_probs[i], weights=quality_scores))\n",
    "        if sum(quality_scores) > 0\n",
    "        else 0\n",
    "    )\n",
    "    corr_w_score = spearmanr(beam_score_log_probs[i], quality_scores).statistic\n",
    "    if str(corr_w_score) == \"nan\":\n",
    "        corr_w_score = 0.0\n",
    "    weighted_avgs.append(weighted_avg)\n",
    "    corr_w_scores.append(corr_w_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.05150370214418871, pvalue=0.10152708135420219)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(weighted_avgs, results.scores_dataframe[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.19976456295383235, pvalue=1.4383123295231031e-10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(corr_w_scores, results.scores_dataframe[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
